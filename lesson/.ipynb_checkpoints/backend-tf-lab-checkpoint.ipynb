{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "876da35c-9842-4bd0-b474-d6189590813d",
   "metadata": {},
   "source": [
    "# Fullstack Terraform Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dade9f7-dffc-4716-9b89-e43f4f05f8d2",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e040d31-650a-4887-8064-be1aa5173074",
   "metadata": {},
   "source": [
    "In this lesson, we'll use terraform to automatically deploy a our flask application to AWS.  In doing this, we'll need to set up an RDS instance, as well as an EC2 instance.  We'll also need to automatically setup our EC2 instance to download the images for the flask backend, the streamlit frontend, and of course start up the containers.\n",
    "\n",
    "Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858e73f-2030-4208-95c7-3b115e9e5410",
   "metadata": {},
   "source": [
    "### Building our backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a0bd2-cf15-4ee9-9037-d41a667163b2",
   "metadata": {},
   "source": [
    "If you look at our llm-scraper codebase, you'll see that we currently have folders for `api` and `frontend`.  These folders are for holding our frontend streamlit application and our backend flask application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f223495-814b-40bc-999c-800dc476f439",
   "metadata": {},
   "source": [
    "Let's start with our backend application.  Inside the api folder, we want it to look like the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bad02b-9c4a-47a6-9085-dd03df2883c5",
   "metadata": {},
   "source": [
    "```bash\n",
    "Dockerfile\n",
    ".env\n",
    ".flaskenv\n",
    "├── app\n",
    "│   ├── __init__.py\n",
    "│   ├── data\n",
    "│   ├── models\n",
    "│   ├── requirements.txt\n",
    "│   ├── server.py\n",
    "│   ├── settings.py\n",
    "│   └── setup.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393b6b26-d00a-41dc-8eed-656ec5b1743b",
   "metadata": {},
   "source": [
    "* So notice that we moved the `.env`, `.flaskenv`, `server.py` files into the api folder, as everything here is specific to the api.\n",
    "* We also changed variables like `dev_db` to `db_conn` in our `server.py` file, and changed `DEV_DB` to `DB_CONN` in the `.env` file.  This makes sense as we will not always be connecting to the development database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3521a84-6210-4a8f-851f-be7c44c71a91",
   "metadata": {},
   "source": [
    "Now, we cannot directly just build our codebase in a Docker image -- as there is some initial setup that we'll need to complete.  Namely, we'll want to add code that will allow our flask application to setup our database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc5d406-2320-4480-9c2d-97b6efbb3b50",
   "metadata": {},
   "source": [
    "* Database setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8850b4b0-2015-4411-b307-3646c94f9fce",
   "metadata": {},
   "source": [
    "To do this we'll add two methods into the `server.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a7b7fd-ec03-4bbb-ac56-071a34f9a4b6",
   "metadata": {},
   "source": [
    "```python\n",
    "@app.cli.command(\"init-db\")\n",
    "def init_db_command():\n",
    "    \"\"\"Create database tables and seed data.\"\"\"\n",
    "    db.create_all()\n",
    "\n",
    "# seed-db command\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4ef5f8-f540-4b33-a0f6-be125eb349f3",
   "metadata": {},
   "source": [
    "Ok, so the first function adds a cli command called `init-db` that will create all of the tables -- derived from our sqlalchemy models.  \n",
    "\n",
    "> Give it a shot by setting the environmental variables to connect to a local database.  (You can just create a new database, and replace the `db_conn` variable with the connection to the database.  For example, if you connect to postgres, and create a database called `sample_scraper`.\n",
    "\n",
    "You can comment out the original db_conn, and update `db_conn` to be:\n",
    "\n",
    "`db_conn = 'postgresql://localhost/sample_scraper'`\n",
    "\n",
    "Then from the folder that has `server.py` defined, run `flask init-db`, and the connect to the `sample_scraper` database to confirm that both the positions and scrapings tables have been created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9e18d2-aef6-4438-b10a-69abbc76d202",
   "metadata": {},
   "source": [
    "> <img src=\"./sample_tables.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1aff4-ed26-4ec3-ac9e-bc15b365dd23",
   "metadata": {},
   "source": [
    "Next will be your turn to add a command line function.  In the `server.py` file, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e60f87-45f8-402b-8eca-47368a73186d",
   "metadata": {},
   "source": [
    "The command should be `seed-db`, which should decorate a function called `seed_db` which does the following:\n",
    "\n",
    "* Counts the number of scrapings\n",
    "* Counts the number of positions\n",
    "* prints the number of scrapings and positions with some text like, \"`Will seed scrapings and positions if there are none in the db.  Currently there are ... scrapings and ... positions`\"\n",
    "* Then only seed scrapings if there are zero in the database, and only seed positions if there are zero in the database.\n",
    "* use the `seed_scrapings_from_csv` and `seed_positions_from_csv` functions, which are already defined in the `setup.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32d9ea6-62c5-4452-85e6-29079a23217c",
   "metadata": {},
   "source": [
    "Test out your function by calling `seed-db` from the command line and confirm that there are scrapings and positions in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f30376b-ada8-4592-9ada-ba5dafff44c6",
   "metadata": {},
   "source": [
    "Also, call `flask run`, and visit `localhost:5000/positions` to confirm that our flask api is serving our seeded positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495915a-416c-433b-adad-9f992e1655e8",
   "metadata": {},
   "source": [
    "* **Reset the db_conn:** Ok, so now we'll want to go back to the `settings.py` file, and make sure we are back to using our original `db_conn` string.\n",
    "\n",
    "```python\n",
    "db_conn = f'postgresql://{username}:{password}@{host}/{database}'\n",
    "```\n",
    "\n",
    "This is because we want to make sure that our db_conn string references the environmental variables, as docker will let us to pass environmental variables when we boot up our container.\n",
    "\n",
    "> Note: Even if we have environmental variables in the `.env` file, any environmental variables we specify with the `docker run -e ` command will overwrite those in the `.env` file.  This is a good thing -- it allows us to change those variables more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb436834-67de-495f-bb21-8fcd0b608747",
   "metadata": {},
   "source": [
    "* Set up an AWS database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a050587-f027-4989-b051-779e726a3b4e",
   "metadata": {},
   "source": [
    "At this point, it's probably good to set up an rds instance, and record the variables of `username`, `password`, `host`, and `database`.  You can place them in the `.env` file if you like, or pass them when booting up the container (ie. at runtime). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24848c0-970a-48d7-939f-10d17a6a15de",
   "metadata": {},
   "source": [
    "### Setting up docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fc9de-a4ed-45bb-a625-5dbc5661fbcb",
   "metadata": {},
   "source": [
    "Ok, so now let's build the docker image.  The Dockerfile is a little tricky, so we have done this for you.  The key issue is that we want multiple things to occur when we boot up our docker container (aka \"at runtime\").  When we create a docker container we want to:\n",
    "\n",
    "* Create our database tables (if they do not already exist)\n",
    "* Seed our `positions` and `scrapings` tables if they do not already have data in them.\n",
    "* Run our flask application by default.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f8fdd-2df0-4d9a-adee-86b519ad01f1",
   "metadata": {},
   "source": [
    "Ok, so to achieve this we do a couple of things:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957824f0-9be5-4fa4-8774-484deccbc867",
   "metadata": {},
   "source": [
    "1. Using entrypoint and command in our Dockerfile\n",
    "\n",
    "If you look at the Dockerfile, you'll see the following towards the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909fd14-e8fc-447b-ae8a-b051252788b1",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "ENTRYPOINT [\"sh\", \"./setup.sh\"]\n",
    "\n",
    "CMD [\"flask\", \"run\", \"--host=0.0.0.0\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd5d25f-bd2c-4163-ac71-100d5c18b5d1",
   "metadata": {},
   "source": [
    "The `Entrypoint` is always run at run time, and CMD are the default arguments passed to what's specified in entrypoint.  So in this case, it's as if we are doing:\n",
    "\n",
    "`sh ./setup.sh flask run --host=0.0.0.0`\n",
    "\n",
    "So this will run the `./setup.sh` and then pass `flask run --host=0.0.0.0` to that file.\n",
    "\n",
    "What will the `setup.sh` file do with the `flask run --host=0.0.0.0` argument?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5308aaf1-71dd-4ccf-b7da-8951e8c92d7f",
   "metadata": {},
   "source": [
    "2. `setup.sh` file\n",
    "\n",
    "If you look at the setup.sh file you'll see the following:\n",
    "\n",
    "```bash\n",
    "flask init-db\n",
    "flask seed-db\n",
    "\n",
    "exec \"$@\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e4db4d-ca2d-4a30-91aa-234fb13bc7f9",
   "metadata": {},
   "source": [
    "So this will call our `init-db` and `seed-db` functions to create and seed our tables.  The `exec \"$@\"` allows us to pass optional bash commands to the script.  So when we setup our Dockerfile to run the script with:\n",
    "\n",
    "`sh ./setup.sh flask run --host=0.0.0.0`\n",
    "\n",
    "The arguments of `flask run --host=0.0.0.0` will be run in that last line.\n",
    "\n",
    "We can play around with this.  For example, if we run `sh setup.sh echo hello world`, then we will have created and seeded our tables and run displayed hello world at the end.\n",
    "\n",
    "So in this scenario, the `CMD [\"flask\", \"run\", \"--host=0.0.0.0\"]` says to pass `flask run --host=0.0.0.0` to our entrypoint `sh setup.sh`, and then the `setup.sh` file executes the `flask run` command after first creating the tables and seeding the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3611694-5a83-41f8-bedb-c082ceb1ee95",
   "metadata": {},
   "source": [
    "And remember we can override that default command at run time with something like:\n",
    "\n",
    "`docker run image_name flask run --debug=True`\n",
    "\n",
    "And that means that the setup.sh script will catch those arguments and run that instead of the original command."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e47b5-c664-44de-a511-6e11984cb8c9",
   "metadata": {},
   "source": [
    "* Building our image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da226523-5bb2-4650-9d2d-3e9b285ab515",
   "metadata": {},
   "source": [
    "Ok, so back to the show.  Now build the image, but do so with tagging the image with your dockerhub usernamem first.  Here's an example, so swap our `jek2141` with your username.\n",
    "\n",
    "```bash\n",
    "docker build -t jek2141/scraper_backend .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d31efc8-b67f-44d8-a0a6-9c78c25ca6c1",
   "metadata": {},
   "source": [
    "So now we'll want to bootup our image locally before trying it on our ec2 instance, but doing so will be a fairly long line.  So you may want to write it out in the `ec2-setup.sh` file, and the copy and paste it into your terminal.  \n",
    "\n",
    "Ok, so boot up your container, but make sure you pass through environmental variables `docker build -e` for all of the database environmental variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf440dd-65fd-4d9a-ab69-613b85c8940b",
   "metadata": {},
   "source": [
    "If it works, you should be able to go to `localhost:5000/positions` and see the positions in the flask application.  \n",
    "\n",
    "* Make sure that your environmental variables are properly getting passed through by passing through some incorrect information (like a wrong password) that should cause your application to break.  If this doesn't work it means you are likely reading from the .env file but not from your `docker build -e` arguments.\n",
    "\n",
    "Once you have a docker run command that is properly working, copy it into your `ec2-setup.sh` file, as you'll want this (or something like it) later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9312d6-515b-4d40-a416-f7b973f82002",
   "metadata": {},
   "source": [
    "* One more thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3108439-71b7-4773-a558-b9d284606015",
   "metadata": {},
   "source": [
    "Now we're about to move onto terraform, but there is one issue with our docker image that we'll likely run into.  It's that there may be a mismatch between our laptop where we built our image on and the ec2 machine we ultimately use.  So before moving on, let's rebuild the image and tag it.  \n",
    "\n",
    "> Just replace `jek2141` with your username.\n",
    "\n",
    "`docker build -t jek2141/scraper_backend:amd_v2 --platform=linux/amd64/v2 .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acde977-20cd-4a6c-b75d-cc47cfd42bec",
   "metadata": {},
   "source": [
    "And now this is the image we'll ultimate want to use on our ec2 machine, so let's push it up to dockerhub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204f2aac-5e1a-4e24-b4a5-e4329d0ff0f1",
   "metadata": {},
   "source": [
    "`docker push jek2141/scraper_backend:amd_v2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d8b34-02b3-465e-be15-cd2ed47d6cd5",
   "metadata": {},
   "source": [
    "### Moving to Terraform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15371695-cd8d-4e6d-8a61-10079a420b42",
   "metadata": {},
   "source": [
    "Ok, so now we're ready to try building our terraform infrastructure.  \n",
    "\n",
    "**A. Setting up the database**\n",
    "\n",
    "Ok, so we did a good amount of the work on the rds instance.  You can see it setup in the `tf/rds.tf` file.  Here's what you'll still need to do:\n",
    "    \n",
    "1. Use local variables\n",
    "    * So currently `db_name`, `username`, `password` and `db_name` are hardcoded.  Move to using the local variables that are defined above.\n",
    "    * In production you can look into using the aws secrets manager, or you could imagine just having the local variables in a `tf` file that is in a .gitignore and so not pushed up to github.  But you can skip that.\n",
    "\n",
    "2. Attach the security group \n",
    "\n",
    "* We already declared a security group for you, and notice that we also set `publicly_accessible = true`.  Still, you'll need to *attach* the security group to the rds instance.\n",
    "\n",
    "You can do this by adding a property of:\n",
    "\n",
    "* `vpc_security_group_ids` and associating the security group id from the security group defined in the file.\n",
    "\n",
    "**Todo**: Add RDS in the file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b7406a-0bb2-4429-94e3-07d47a64e75a",
   "metadata": {},
   "source": [
    "**B. Setting up the EC2 instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7fa6961-9047-4861-9622-4f32c9a501af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jeffreykatz/Documents/jigsaw/curriculum/terraform/7-tf-fullstack/lesson'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f42f9-ec2c-486f-80f1-9150dc71927f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> Later will need to add the : \n",
    "    \n",
    "`security_groups = [aws_security_group.web_app.id]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7bf71-dab8-4e76-8e0f-728c26ae96d4",
   "metadata": {},
   "source": [
    "`docker build -t jek2141/scraper_backend --platform=linux/amd64/v2 .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1dc63-fa68-4066-9200-001dedb68844",
   "metadata": {},
   "source": [
    "* `flask run`\n",
    "* Add command lines arguments in the \n",
    "\n",
    "2. Switch to a production database\n",
    "\n",
    "Fill in the .env file\n",
    "\n",
    "3. Get working with docker\n",
    "\n",
    "* We encoded this in a entrypoint.sh file\n",
    "* `cd ./api`\n",
    "* `docker build -t scraper_backend .`\n",
    "* Notice the difference with entrypoint vs cmd functions\n",
    "\n",
    "Notice that we can override any of the environmental variables with the -e flag\n",
    "\n",
    "* docker run -p 5000:5000 -e DB_PASSWORD=foobar scraper_backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beaac8f-7e09-4802-89e5-789995cfab95",
   "metadata": {},
   "source": [
    "* Connect the streamlit frontend app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87596267-642d-453e-88f6-59a9220c2024",
   "metadata": {},
   "source": [
    "* Notice in the docker file\n",
    "\n",
    "* in the index \n",
    "* `st.write('hello all')`\n",
    "* `CMD [\"streamlit\", \"run\", \"./index.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563baf9-517f-4d26-85b0-4be59be2b628",
   "metadata": {},
   "source": [
    "* `docker run -p 8503:8501 scraper_frontend`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff426b-77db-47bc-85b7-4a6c2b8b7bce",
   "metadata": {},
   "source": [
    "Then connect frontend to backend."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3411949c-3c8e-4c7b-8d7f-75ef272074d2",
   "metadata": {},
   "source": [
    "* `docker network create my-network`\n",
    "\n",
    "* `docker run -p 5000:5000 --network my-network --name backend scraper_backend`\n",
    "\n",
    "* `docker run -p 8503:8501 --network my-network scraper_frontend`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a37409-12cf-453e-b8b4-92ed1cb2970d",
   "metadata": {},
   "source": [
    "* Create a `ec2-setup.sh` file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe21780f-bbfc-45d4-8bd7-56fa2210a7ff",
   "metadata": {},
   "source": [
    "Now that we understand how if else and echo works, update the shell script so that it only will stop and remove the container if the backend container already exists.  And applies a separate if block for the frontend container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e543b38-6d1e-4595-a098-33791583d4d8",
   "metadata": {},
   "source": [
    "* Update by pushing to dockerhub, and then update script to pull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd9754-03e3-4acc-8343-ac565f8bd1e1",
   "metadata": {},
   "source": [
    "* Update the docker run backend script to pass through env variables -- declare them as variables up top, and then reference them in the backend script.\n",
    "\n",
    "* Confirm that connects to the rds database with DB_HOST\n",
    "* Then go to localhost to confirm frontend works\n",
    "* And exec into the backend machine, and make sure the DB_HOST environmental variable is properly set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3267dff6-3524-4e4c-8530-79abe5d7ef76",
   "metadata": {},
   "source": [
    "> <img src=\"./db-host-env.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900efa08-24d9-4884-8874-bb2b0e26b391",
   "metadata": {},
   "source": [
    "### Moving to Terraform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9833c894-1f27-4f6d-9084-09213358379b",
   "metadata": {},
   "source": [
    "1. Create the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94d2c3e-2fac-496e-b220-423ca77e3b33",
   "metadata": {},
   "source": [
    "* Confirm that you can access it by using `psql` to access from the command line.  Confirm that there is a database called `job_scraper`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f84caf6-4c2b-4c4e-a1f5-6ec9e86ea55e",
   "metadata": {},
   "source": [
    "> <img src=\"./job-scraper-access.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1b74e7-4c7f-4ba3-9548-0fad2411e79b",
   "metadata": {},
   "source": [
    "2. Creates the ec2 instance and make sure we have database access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903eec7-a155-4d70-a28e-4d6b35f4d7cb",
   "metadata": {},
   "source": [
    "To achieve this, on the database's security group, we should add a `security_groups` tag of the ec2 instance's security group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1849821-4ea1-4405-9d3d-9948094b1e34",
   "metadata": {},
   "source": [
    "```bash\n",
    "resource \"aws_security_group\" \"postgres_access\" {\n",
    "  name = \"scraper psql access\"\n",
    "  ingress {\n",
    "    from_port   = 5432\n",
    "    to_port     = 5432\n",
    "    protocol    = \"tcp\"\n",
    "    cidr_blocks = [\"0.0.0.0/0\"]\n",
    "    security_groups = [aws_security_group.web_app.id]\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18c5609-b185-469c-92e4-923a3bdceb73",
   "metadata": {},
   "source": [
    "For example, above, notice that we not only give access on any port with the `0.0.0.0` but also give access to those resources that have a security group of `aws_security_group.web_app.id`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc5aec-1c7e-49f0-a1e5-15d637d99608",
   "metadata": {},
   "source": [
    "* Confirm we can access from our ec2 machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa84f0-5961-444d-b552-59c32adaa8eb",
   "metadata": {},
   "source": [
    "* sudo apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2423c17-ed38-438b-9ef6-edfcd5bc584f",
   "metadata": {},
   "source": [
    "<img src=\"./psql-access.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd60e99-e4fd-424a-abb2-f3c8138e577f",
   "metadata": {},
   "source": [
    "* sudo apt-get install postgresql-client-common\n",
    "* sudo apt-get install postgresql-client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd442c0-b814-4f3b-9c65-4dd02b5194f6",
   "metadata": {},
   "source": [
    "Then let's make sure the rest of our setup steps work on our ec2 machine.  As each is successful, add it to the `ec2-setup.sh` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4124e588-e537-4f53-80d0-d31767417097",
   "metadata": {},
   "source": [
    "* `sudo apt-get install docker -Y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98bb28-d582-4b32-935e-4b182e32fde7",
   "metadata": {},
   "source": [
    "This looked like it worked, but if we run, `docker --version` to confirm it's installed, we see that it isn't available.  Let's try a different way of installing docker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d438c40-b96f-4c29-b5be-1ecaf16b721d",
   "metadata": {},
   "source": [
    "`sudo snap install docker`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947586e-582c-4c09-8ab9-009b0ddde70b",
   "metadata": {},
   "source": [
    "Then confirm that this worked, by again running `docker --version`.  Ok, if this was successful, add it to the `ec2-setup.sh` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02bc75-0a40-42ff-9a31-4cf8ed6475b9",
   "metadata": {},
   "source": [
    "And `sudo docker ps` shows that it is up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f105151-8e06-4b38-ad58-bcbcd908230c",
   "metadata": {},
   "source": [
    "* So now let's scp our script over to the ec2 machine, and confirm that it works on the ec2 machine.\n",
    "    > Before doing so, make sure the `DB_HOST` variable and `DB_NAME` point to the correct names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d47300-de2d-4f00-9270-b92b3ef8e4f1",
   "metadata": {},
   "source": [
    "```bash\n",
    "scp -i ~/.ssh/example.pem ./ec2-setup.sh  ubuntu@ec2-3-86-210-55.compute-1.amazonaws.com:/home/ubuntu/ec2-setup.sh\n",
    "# ec2-setup.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9c820e-7236-4053-b797-70b61b42a852",
   "metadata": {},
   "source": [
    "* `sudo sh ec2-setup.sh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40857d9c-eff6-4163-847d-ba8d71d71f9e",
   "metadata": {},
   "source": [
    "Unfortunately fails on the following lines\n",
    "\n",
    "* `docker run -d -p 5000:5000 --network $NETWORK_NAME --name $BACKEND_CONTAINER -e DB_USERNAME=$DB_USERNAME -e DB_PASSWORD=$DB_PASSWORD -e DB_NAME=$DB_NAME -e DB_HOST=$DB_HOST $BACKEND_IMAGE`\n",
    "\n",
    "And this is because there is a mismatch where the software is `linux/amd64/v2`\n",
    "\n",
    "Ideally we would specify to rebuild with \n",
    "* `docker build -t jek2141/scraper_backend:amd_v2 --platform=linux/amd64/v2 .`\n",
    "* `docker build -t jek2141/scraper_frontend:amd_v2 --platform=linux/amd64/v2 .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e52d52-0a8e-4a0b-afc2-0c8b1e61355d",
   "metadata": {},
   "source": [
    "* Confirm it works with:\n",
    "    \n",
    "`curl localhost:5000/positions`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0cd842-345b-4b9b-a615-c3ed1380738f",
   "metadata": {},
   "source": [
    "* Then move to a template file (and add the `depends on`)\n",
    "\n",
    "* Check the console\n",
    "    * terraform console data.rendered \n",
    "    \n",
    "* Make sure to replace any call to docker with `sudo docker`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0c859-a98a-45ec-8be0-bbded88f287a",
   "metadata": {},
   "source": [
    "```bash\n",
    "cat /var/log/cloud-init-output.log\n",
    "cat /var/log/cloud-init.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80616c59-8b98-4886-81fc-8cb0c78c4a88",
   "metadata": {},
   "source": [
    "* Expose ports to the api, and ports to the "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568fe8a5-df6c-4ff7-9718-33cf6b6c8cef",
   "metadata": {},
   "source": [
    "* removed\n",
    "```\n",
    "while ! nc -z $DB_HOST 5432; do\n",
    "    echo 'Waiting for DB to be ready'\n",
    "    sleep 5\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ba941b-874d-4a58-912e-e97095fe6ef8",
   "metadata": {},
   "source": [
    "<img src=\"./complete-deployment.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f795aa-34cd-4a6a-91c0-c2c5c8b300d7",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Terraform working with Following](https://discuss.hashicorp.com/t/template-v2-2-0-does-not-have-a-package-available-mac-m1/35099/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5b27c7-2e04-48e3-be18-489d037bf35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
